# Tiny LLM

Welcome to **Tiny LLM** - a step-by-step guide to understanding how Large Language Models work by building one from scratch!

This project breaks down the complex process of creating an LLM into easy-to-follow steps. Each step is documented in its own file to make learning digestible and organized.

## Table of Contents

### [Step 1: Corpus Creation](STEP_1_CORPUS.md)
Learn how to gather and prepare high-quality text data that will serve as the foundation for your LLM. We'll download the Tiny Shakespeare dataset and understand what makes a good corpus.

**What you'll learn:**
- What is a corpus and why it matters
- How to download and prepare training data
- Quality considerations for text datasets

---

### [Step 2: Creating a Tokenizer](STEP_2_TOKENIZER.md)
Understand how to convert text into numbers that neural networks can process. You'll build a character-level tokenizer from scratch.

**What you'll learn:**
- What tokenization is and why it's necessary
- How to build a character-level tokenizer
- Key concepts: vocabulary, encoding, decoding
- Different types of tokenization (character, word, subword)

---

## Getting Started

1. Clone this repository
2. Start with [Step 1: Corpus Creation](STEP_1_CORPUS.md)
3. Work through each step sequentially
4. Run the code examples as you learn

## Requirements

```bash
pip install requests
```

---

**Happy Learning! ðŸš€**
